---
title: "VDAP Analysis"
author: "Halee Staggs"
date: "2022-11-23"
output: pdf_document
---

```{r global.options, include = FALSE}
knitr::opts_chunk$set(
    cache       = TRUE,     # if TRUE knitr will cache the results to reuse in future knits
    fig.align   = 'center', # how to align graphics in the final doc. 'left', 'right', 'center'
    fig.path    = 'figs/',  # file path to the directory where knitr shall store the graphics files
    results     = 'asis',   # knitr will pass through results without reformatting them
    echo        = TRUE,     # in FALSE knitr will not display code in the code chunk above it's results
    message     = FALSE,     # if FALSE knitr will not display any messages generated by code
    strip.white = TRUE,     # if FALSE knitr will not remove white spaces at the beg or end of code chunk
    warning     = FALSE) 
```

# Import Packages

```{r}
#install.packages('corrplot')
library('corrplot')
#install.packages('readr')
library('readr')
#install.packages('stats')
library('stats')
#install.pacakges('cluster')
library('cluster')
#install.packages('factoextra')
library('factoextra')
#install.packages('tidyr')
library('tidyr')
#install.packages('FactoMineR')
library('FactoMineR')
#install.packages('devtools')
library('devtools')
#install.packages('Hmisc')
library('Hmisc')
#install.packages('descr')
library('descr')
#install.packages('ggpubr')
library('ggpubr')
#install.packages('ggplot2')
library('ggplot2')
#install.packages('psych')
library('psych')
#install.packages('tidyverse')
library('tidyverse')
#install.packages('MatchIt')
library('MatchIt')
#install.packages('optmatch')
library('optmatch')
#install.packages('data.table')
library('data.table')
#install.packages('knitr')
library('knitr')
#install.packages('car')
library('car')
#install.packages('FSA')
library('FSA')
#install.packages("lme4")
library('lme4')
#install.packages('lmerTest')
library('lmerTest')
#install.packages('sjstats')
library('sjstats')
library(neuralnet)
library(caret)
library(e1071)
library(C50)
```

# Set seed for reproducibility
```{r}
set.seed(2)
```

# Read in data files
```{r}
mood <- read_csv("C:/Users/halee/OneDrive/Desktop/vdap_cut.csv")

#View(mood)
```

# Check NAs and descriptives
```{r}
#describe(mood)
summary(mood)
```

# Fill NA values with appropriate measure
```{r}
mood$gor_id[is.na(mood$gor_id)] <- 0
mood$age[is.na(mood$age)] <- median(mood$age, na.rm=TRUE)
mood$sex[is.na(mood$sex)] <- max(mood$sex, na.rm = TRUE)
mood$ethnicity[is.na(mood$ethnicity)] <- median(mood$ethnicity, na.rm = TRUE)
mood$pre_race[is.na(mood$pre_race)] <- median(mood$pre_race, na.rm = TRUE)
mood$area_type[is.na(mood$area_type)] <- median(mood$area_type, na.rm = TRUE)
mood$edu_1[is.na(mood$edu_1)] <- median(mood$edu_1, na.rm = TRUE)
mood$edu_2[is.na(mood$edu_2)] <- median(mood$edu_2, na.rm = TRUE)
mood$alcohol_status[is.na(mood$alcohol_status)] <- median(mood$alcohol_status, na.rm = TRUE)
mood$psychiatric_hist_status[is.na(mood$psychiatric_hist_status)] <- min(mood$psychiatric_hist_status, na.rm = TRUE)
mood$verify_veteran[is.na(mood$verify_veteran)] <- min(mood$verify_veteran, na.rm=TRUE)
mood$pf_total[is.na(mood$pf_total)] <- median(mood$pf_total, na.rm = TRUE)
mood$drive[is.na(mood$drive)] <- median(mood$drive, na.rm = TRUE)
mood$fun[is.na(mood$fun)] <- median(mood$fun, na.rm = TRUE)
mood$reward[is.na(mood$reward)] <- median(mood$reward, na.rm = TRUE)
mood$bis[is.na(mood$bis)] <- median(mood$bis, na.rm = TRUE)
mood$bis_total[is.na(mood$bis_total)] <- median(mood$bis_total, na.rm = TRUE)
mood$nicotine[is.na(mood$nicotine)] <- median(mood$nicotine, na.rm=TRUE)
mood$cannabis[is.na(mood$cannabis)] <- median(mood$cannabis, na.rm=TRUE)
mood$masq_anxious[is.na(mood$masq_anxious)] <- median(mood$masq_anxious, na.rm=TRUE)
mood$masq_arousal[is.na(mood$masq_arousal)] <- median(mood$masq_arousal, na.rm=TRUE)
mood$masq_anhedonic[is.na(mood$masq_anhedonic)] <- median(mood$masq_anhedonic, na.rm=TRUE)
mood$masq_total[is.na(mood$masq_total)] <- median(mood$masq_total, na.rm=TRUE)
mood$debq_restrained[is.na(mood$debq_restrained)] <- median(mood$debq_restrained, na.rm=TRUE)
mood$debq_emotional[is.na(mood$debq_emotional)] <- median(mood$debq_emotional, na.rm=TRUE)
mood$debq_external[is.na(mood$debq_external)] <- median(mood$debq_external, na.rm=TRUE)
mood$debq_total[is.na(mood$debq_total)] <- median(mood$debq_total, na.rm=TRUE)
mood$meds[is.na(mood$meds)] <- 0
mood$med1[is.na(mood$med1)] <- 0
mood$med2[is.na(mood$med2)] <- 0
mood$med3[is.na(mood$med3)] <- 0
mood$med4[is.na(mood$med4)] <- 0
mood$med5[is.na(mood$med5)] <- 0
mood$med6[is.na(mood$med6)] <- 0
mood$med98[is.na(mood$med98)] <- 0
mood$mdd[is.na(mood$mdd)] <- 0
mood$mad[is.na(mood$mad)] <- 0
mood$ptsd[is.na(mood$ptsd)] <- 0
mood$adhd[is.na(mood$adhd)] <- 0
mood$bipol[is.na(mood$bipol)] <- 0
mood$pd[is.na(mood$pd)] <- 0
mood$diag_year[is.na(mood$diag_year)] <- median(mood$diag_year, na.rm=TRUE)
```


# Update categorical variables to factors
```{r}
mood$verify_veteran <- as.factor(mood$verify_veteran)
mood$ethnicity <- as.factor(mood$ethnicity)
mood$pre_race <- as.factor(mood$pre_race)
mood$area_type <- as.factor(mood$area_type)
mood$edu_1 <- as.factor(mood$edu_1)
mood$edu_2 <- as.factor(mood$edu_2)
mood$nicotine <- as.factor(mood$nicotine)
mood$alcohol_status <- as.factor(mood$alcohol_status)
mood$cannabis <- as.factor(mood$cannabis)
```

# Transform diagnosis year to duration of mental illness diagnosis
```{r}
mood$diag_dur <- 2022 - mood$diag_year
mood$diag_dur[is.na(mood$diag_dur)] <- median(mood$diag_dur, na.rm=TRUE)
```


# Combine people on psychiatric meds into one group and update to a factor variable
```{r}
mood$med_total <- mood$med1 + mood$med2 + mood$med4 + mood$med5
mood$med_group <- mood$med_total > 0
mood$med_group <- as.factor(mood$med_group)
#View(mood)
#str(mood)
```

# Create single diagnosis group, comorbid group, trimorbid group, and psychiatric history group
```{r}
mood$axis1_total <- mood$mdd + mood$mad + mood$ptsd + mood$adhd + mood$bipol + mood$pd

#single disorder
mood$axis1 <- mood$axis1_total == 1
mood$axis1 <- as.factor(mood$axis1)

#comorbid
mood$axis2 <-  mood$axis1_total == 2
mood$axis2 <- as.factor(mood$axis2)

#trimorbid or more
mood$axis3 <-  mood$axis1_total > 2
mood$axis3 <- as.factor(mood$axis3)

#undiagnosed: psych_hist = 0 
mood$diag <- mood$psychiatric_hist_status == 1
mood$diag <- as.factor(mood$diag)
```

# Update variables to factor
```{r}
mood$psychiatric_hist_status <- as.factor(mood$psychiatric_hist_status)
mood$meds <- as.factor(mood$meds)
mood$med1 <- as.factor(mood$med1)
mood$med2 <- as.factor(mood$med2)
mood$med3 <- as.factor(mood$med3)
mood$med4 <- as.factor(mood$med4)
mood$med5 <- as.factor(mood$med5)
mood$med6 <- as.factor(mood$med6)
mood$med98 <- as.factor(mood$med98)
mood$mdd <- as.factor(mood$mdd)
mood$mad <- as.factor(mood$mad)
mood$ptsd <- as.factor(mood$ptsd)
mood$adhd <- as.factor(mood$adhd)
mood$bipol <- as.factor(mood$bipol)
mood$pd <- as.factor(mood$pd)
```

# Verify NAs filled and all values are updated
```{r}
summary(mood)
#View(mood)
```


# Remove all records without item level PHQ and GAD data, left with n = 197. Check out dataframe and data structures.
```{r}
mood_rm_na <- drop_na(mood)
#View(mood_rm_na)
#str(mood_rm_na)
```


# Correlation matrix for numerical variables
```{r}
numerical_index <- c(3,15,28,70:80)
mood_cor <- cor(mood_scale[,c(3,15,28,70:80)])
corrplot(mood_cor, method = 'number', tl.cex = .7, number.cex = .7 )
```

# Distributions for numerical variables
```{r}
boxplot(mood_rm_na$age, main = "AGE Dist")
boxplot(mood_rm_na$pf_total, main = "PF Dist")
boxplot(mood_rm_na$bis_total, main = "BIS Dist")
boxplot(mood_rm_na$masq_total, main = "MASQ Dist")
boxplot(mood_rm_na$debq_total, main = "DEBQ Dist")
boxplot(mood_rm_na$phq_score, main = "PHQ Dist")
boxplot(mood_rm_na$gad_score, main = "GAD Dist")
boxplot(mood_rm_na$diag_dur, main = "DIAG_DUR Dist")
```

# Data descriptives
```{r}
#demographics
mean(mood_rm_na$age)
median(mood_rm_na$age)
sd(mood_rm_na$age)
min(mood_rm_na$age)
max(mood_rm_na$age)

median(mood_rm_na$axis1_total)
min(mood_rm_na$axis1_total)
max(mood_rm_na$axis1_total)

prop.table(table(mood_rm_na$verify_veteran))
prop.table(table(mood_rm_na$sex))
prop.table(table(mood_rm_na$ethnicity))
prop.table(table(mood_rm_na$pre_race))
prop.table(table(mood_rm_na$area_type))
prop.table(table(mood_rm_na$edu_2))
prop.table(table(mood_rm_na$psychiatric_hist_status))
prop.table(table(mood_rm_na$meds))

#self report measures
mean(mood_rm_na$pf_total)
median(mood_rm_na$pf_total)
sd(mood_rm_na$pf_total)
min(mood_rm_na$pf_total)
max(mood_rm_na$pf_total)

mean(mood_rm_na$bis_total)
median(mood_rm_na$bis_total)
sd(mood_rm_na$bis_total)
min(mood_rm_na$bis_total)
max(mood_rm_na$bis_total)

mean(mood_rm_na$masq_total)
median(mood_rm_na$masq_total)
sd(mood_rm_na$masq_total)
min(mood_rm_na$masq_total)
max(mood_rm_na$masq_total)

mean(mood_rm_na$phq_score)
median(mood_rm_na$phq_score)
sd(mood_rm_na$phq_score)
min(mood_rm_na$phq_score)
max(mood_rm_na$phq_score)

mean(mood_rm_na$gad_score)
median(mood_rm_na$gad_score)
sd(mood_rm_na$gad_score)
min(mood_rm_na$gad_score)
max(mood_rm_na$gad_score)

```


# GAD/PHQ item correlations
```{r}
mood_item_index <- c(31:45)
item_cor <- cor(mood_scale[mood_item_index])
corrplot(item_cor, method = 'number', tl.cex = .7, number.cex = .7)
```

# Replication correlation between PHQ and GAD colored by each categorical variable
```{r}
kable(as.matrix(cor.test(mood$phq_score, mood$gad_score)))
```

# Scatter plots visualizations for global scores and demographics
```{r}
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'ethnicity', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'pre_race', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'edu_1', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'edu_2', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'nicotine', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'cannabis', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'alcohol_status', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'psychiatric_hist_status', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'meds', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'med1', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'med2', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'med3', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'med4', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'med5', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'med6', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'med98', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'mdd', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'mad', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'ptsd', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'adhd', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'bipol', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'pd', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'med_group', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'axis1', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'axis2', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'axis3', size = 5) + geom_point() + stat_cor()
#ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'diag', size = 5) + geom_point() + stat_cor()
ggscatter(mood_rm_na, 'phq_score', 'gad_score', size = 5) + geom_point() + stat_cor()
ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'area_type', size = 5) + geom_point() + stat_cor()
ggscatter(mood_rm_na, 'phq_score', 'gad_score', color = 'verify_veteran', size = 5) + geom_point() + stat_cor()
```

# Frequency tables for demographics (can compare up to 3 variables), use for visualizations and/or descriptive stat percentage table for final paper
```{r}
#table1 <- table(mood_rm_na$verify_veteran)
#ftable(table1)
#prop.table(table1)

#table2 <- table(mood_rm_na$sex)
#ftable(table2)
#prop.table(table2)

#table3 <- table(mood_rm_na$ethnicity)
#ftable(table3)
#prop.table(table3)

#table4 <- table(mood_rm_na$area_type)
#ftable(table4)
#prop.table(table4)

#table5 <- table(mood_rm_na$pre_race)
#ftable(table5)
#prop.table(table5)

#table6 <- table(mood_rm_na$edu_1)
#ftable(table6)
#prop.table(table6)

#table7 <- table(mood_rm_na$edu_2)
#ftable(table7)
#prop.table(table7)

#table8 <- table(mood_rm_na$nicotine)
#ftable(table8)
#prop.table(table8)

#table9 <- table(mood_rm_na$alcohol_status)
#ftable(table9)
#prop.table(table9)

#table10 <- table(mood_rm_na$cannabis)
#ftable(table10)
#prop.table(table10)

#table11 <- table(mood_rm_na$psychiatric_hist_status)
#ftable(table11)
#prop.table(table11)

#table12 <- table(mood_rm_na$meds)
#ftable(table12)
#prop.table(table12)

#table13 <- table(mood_rm_na$med1)
#ftable(table13)
#prop.table(table13)

#table14 <- table(mood_rm_na$med2)
#ftable(table14)
#prop.table(table14)

#table15 <- table(mood_rm_na$med3)
#ftable(table15)
#prop.table(table15)

#table16 <- table(mood_rm_na$med4)
#ftable(table16)
#prop.table(table16)

#table17 <- table(mood_rm_na$med5)
#ftable(table17)
#prop.table(table17)

#table18 <- table(mood_rm_na$med6)
#ftable(table18)
#prop.table(table18)

#table19 <- table(mood_rm_na$med98)
#ftable(table19)
#prop.table(table19)

#table20 <- table(mood_rm_na$mdd, mood_rm_na$mad)
#ftable(table20)
#prop.table(table20)

#table21 <- table(mood_rm_na$mdd, mood_rm_na$mad, mood_rm_na$ptsd)
#ftable(table21)
#prop.table(table21)

#table22 <- table(mood_rm_na$mdd)
#ftable(table22)
#prop.table(table22)

#table23 <- table(mood_rm_na$mad)
#ftable(table23)
#prop.table(table23)

#table24 <- table(mood_rm_na$ptsd)
#ftable(table24)
#prop.table(table24)

#table25 <- table(mood_rm_na$adhd)
#ftable(table25)
#prop.table(table25)

#table26 <- table(mood_rm_na$bipol)
#ftable(table26)
#prop.table(table26)

#table27 <- table(mood_rm_na$pd)
#ftable(table27)
#prop.table(table27)

#table28 <- table(mood_rm_na$mdd, mood_rm_na$adhd, mood_rm_na$bipol)
#ftable(table28)
#prop.table(table28)

#table29 <- table(mood_rm_na$mad, mood_rm_na$adhd, mood_rm_na$bipol)
#ftable(table29)
#prop.table(table29)

#table30 <- table(mood_rm_na$ptsd, mood_rm_na$adhd, mood_rm_na$bipol)
#ftable(table30)
#prop.table(table30)

#table31 <- table(mood_rm_na$mdd, mood_rm_na$pd)
#ftable(table31)
#prop.table(table31)

#table32 <- table(mood_rm_na$mad, mood_rm_na$pd)
#ftable(table32)
#prop.table(table32)

#table33 <- table(mood_rm_na$ptsd, mood_rm_na$pd)
#ftable(table33)
#prop.table(table33)

#table34 <- table(mood_rm_na$pd, mood_rm_na$bipol, mood_rm_na$adhd)
#ftable(table34)
#prop.table(table34)

#table35 <- table(mood$diag, mood$verify_veteran)
#ftable(table35)
#prop.table(table35)
```



# Principal Component Analysis: Reduce Data Dimensions before clustering
```{r}
corrplot(cor(train))

#pca with rotation on training set
set.seed(2)
pca <- principal(r = train[,69:83], rotate = 'promax', nfactors = 6)
print(pca$loadings, cutoff = 0.49)
round(cor(pca$scores),2)
plot(c(3.366,2.768,1.611,1.580,1.578,1.390),type = 'b',main = 'Plot of Eigen Values - Training',
     ylab = 'Value', xlab = 'Component',ylim = c(0,4));abline(h = 1, lty =2)
pca

#pca with rotation on test set
pca_test <- principal(r = test[,3:17], rotate = 'varimax', nfactors = 6)
print(pca_test$loadings, cutoff = 0.49)
plot(c(3.444,2.920,1.980,1.749,1.703,1.284),type = 'b',main = 'Plot of Eigen Values - Testing',
     ylab = 'Value', xlab = 'Component',ylim = c(0,4));abline(h = 1, lty =2)

```


```{r}
#graph results, can see three-to-five groups of vectors 
#fviz_pca_ind(res.pca,
             #col.ind = "cos2", # Color by the quality of representation
             #gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             #repel = TRUE)

#fviz_pca_var(res.pca,
             #col.var = "contrib", # Color by contributions to the PC
             #gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             #repel = TRUE)

#fviz_pca_biplot(res.pca, repel = TRUE,
                #col.var = "#2E9FDF",
                #col.ind = "#696969")
```

```{r}
#put 3 principal components into a dataframe as variables, and add back to master dataframe
pca_df <- as.data.frame(cbind(pca$scores[,1],pca$scores[,2],pca$scores[,3],pca$scores[,4],pca$scores[,5],pca$scores[,6]))
View(pca_df)
colnames(pca_df)[1] <- 'PC1'
colnames(pca_df)[2] <- 'PC2'
colnames(pca_df)[3] <- 'PC3'
colnames(pca_df)[4] <- 'PC4'
colnames(pca_df)[5] <- 'PC5'
colnames(pca_df)[6] <- 'PC6'

```

# Test optimal number of clusters
```{r}
#elbow method recommends 5 clusters
#fviz_nbclust(train[,69:83], kmeans, method = "wss") + geom_vline(xintercept = 4)

#gap statistic recommends 4 clusters
#gap_stat <- clusGap(train[,69:83], FUN = kmeans, nstart = 25,
                    #K.max = 10, B = 500)
#fviz_gap_stat(gap_stat)
```

```{r}
#run K means function on principal components for 5 cluster solution
#set.seed(2)
#kmeans_mood7 <- kmeans(train[,69:83],centers = 7, nstart = 1000)
#kmeans_mood7
##fviz_cluster(kmeans_mood7, data = train[,69:83], geom = c('point','text')) + theme_classic()

#cluster assignments as grouping variable
#train$cluster7 <- as.factor(kmeans_mood7$cluster)

#cluster visualization with global mood scores 
#ggscatter(mood_clean, 'phq_score','gad_score', color = 'cluster5', size = 5) + labs(title = 'Five Cluster Solution')
```

```{r}

#run K means function on principal components for 4 cluster solution
#kmeans_mood4 <- kmeans(pca_df[,1:2],centers = 4, nstart = 1000)
#kmeans_mood4
#fviz_cluster(kmeans_mood4, data = pca_df[,1:2], geom = c('point','text')) + #theme_classic()
#kmeans_mood4$size

#cluster assignments as grouping variable
#pca_df$cluster4 <- as.factor(kmeans_mood4$cluster)

#cluster visualization with global mood scores 
#ggscatter(mood_clean, 'phq_score','gad_score', color = 'cluster4', size = 5) + labs(title = 'Four Cluster Solution')

```

# Tests for Differences Between Principal Components for 4 Clusters
```{r}
leveneTest(PC1 ~ cluster5, pca_df) #unequal variance
kruskal.test(PC1 ~ cluster5, data = pca_df) #diff between groups for PC1
dunnTest(PC1 ~ cluster5, data = pca_df, method = 'bonferroni') #all significantly different

leveneTest(PC2 ~ cluster5, pca_df) #unequal variance
kruskal.test(PC2 ~ cluster5, data = pca_df) #diff between groups for PC2
dunnTest(PC2 ~ cluster5, data = pca_df, method = 'bonferroni') #none sig diff with correction

#leveneTest(PC3 ~ cluster5, mood_clean) #unequal variance
#kruskal.test(PC3 ~ cluster5, data = mood_clean) #diff between groups for PC3
#dunnTest(PC3 ~ cluster5, data = mood_clean, method = 'bonferroni') #all sig diff except 4 and 5
```


# Create age-matched samples
```{r}
#n = 70
vet_match <- matchit(verify_veteran ~ age, mood_clean, method = "exact")
vet_match_df <- as.data.frame(match.data(vet_match,
  distance = "distance",
  weights = "weights",
  subclass = "subclass",
  data = mood_clean,
  include.s.weights = TRUE))

View(vet_match_df)
```
```{r}
#n = 114
med_match <- matchit(med_group ~ age, mood_clean, method = 'exact')
med_match_df <- as.data.frame(match.data(med_match,
                                         distance = "distance",
                                         weights = "weights",
                                         subclass = "subclass",
                                         data = mood_clean,
                                         include.s.weights = TRUE))

View(med_match_df)
```

```{r}
# n = 108
diag_match <- matchit(diag ~ age + sex, mood_clean, method = 'exact')
diag_match_df <- as.data.frame(match.data(diag_match,
                                         distance = "distance",
                                         weights = "weights",
                                         subclass = "subclass",
                                         data = mood_clean,
                                         include.s.weights = TRUE))

View(diag_match_df)
```

```{r}
# n = 144
diag_match_2 <- matchit(diag ~ age, mood_clean, method = 'exact')
diag_match_df_2 <- as.data.frame(match.data(diag_match_2,
                                          distance = "distance",
                                          weights = "weights",
                                          subclass = "subclass",
                                          data = mood_clean,
                                          include.s.weights = TRUE))

View(diag_match_df_2)
```

```{r}
#n = 136
sex_match <- matchit(sex ~ age, mood_clean, method = 'exact')
sex_match_df <- as.data.frame(match.data(sex_match,
                                          distance = "distance",
                                          weights = "weights",
                                          subclass = "subclass",
                                          data = mood_clean,
                                          include.s.weights = TRUE))
View(sex_match_df)
```


# Chi-Square Testing for demographics against clusters
```{r}
#bin age into categories
mood_scale$age_bin <- cut(mood_scale$age, breaks=4)
```
```{r}
#cluster vs. Vet/Civ
table_a <- table(mood_scale$cluster_cog, mood_scale$verify_veteran)
ftable(table_a)
prop.table(table_a)

chisq.test(table_a) 
x2_cluster_vet <- chisq.test(table_a)

#x2_cluster_vet$expected #not valid, not enough Vet sample

#cluster vs. Sex
table_b <- table(mood_scale$cluster_cog, mood_scale$sex)
ftable(table_b)
prop.table(table_b)

chisq.test(table_b) 
x2_cluster_sex <- chisq.test(table_b)
#x2_cluster_sex$expected #valid, sex difference with whole sample, x2 = 14.698, df = 4, P = .0054

#cluster vs. age-matched sex
#table_b_2 <- table(sex_match_df$cluster5, sex_match_df$sex)
#ftable(table_b_2)
#prop.table(table_b_2)
#chisq.test(table_b_2) 
#x2_cluster_sex_2 <- chisq.test(table_b_2)
#x2_cluster_sex_2$expected #not valid when age-matched, but close 0.07


#cluster vs. age
table_c <- table(mood_scale$cluster_cog, mood_scale$age_bin)
ftable(table_c)
prop.table(table_c)

chisq.test(table_c) 
x2_cluster_age <- chisq.test(table_c)
#x2_cluster_age$expected #only valid with median split, not full range or 6 SD split


#cluster vs. area type
table_d <- table(mood_scale$cluster_cog, mood_scale$area_type)
ftable(table_d)
prop.table(table_d)

chisq.test(table_d) 
x2_cluster_area <- chisq.test(table_d)
#x2_cluster_area$expected #underpowered for rural


#cluster vs. history of psychiatric diagnosis
table_e <- table(mood_scale$cluster, mood_scale$diag)
ftable(table_e)
prop.table(table_e)

chisq.test(table_e) 
x2_cluster_psyhist <- chisq.test(table_e)
#x2_cluster_psyhist$expected #valid, x2 = 41.364, df = 4, p > .001

#cluster vs. age-matched psychiatric diagnosis
#table_e_2 <- table(diag_match_df_2$cluster5, diag_match_df_2$diag)
#ftable(table_e_2)
#prop.table(table_e_2)
#chisq.test(table_e_2) 
#x2_cluster_psyhist_2 <- chisq.test(table_e_2)
#x2_cluster_psyhist_2$expected #barely underpowered by like 1 person, not valid when age and sex matched

#cluster vs. medication use
table_f <- table(mood_scale$cluster, mood_scale$med_group)
ftable(table_f)
prop.table(table_f)

chisq.test(table_f) 
x2_cluster_med <- chisq.test(table_f)
#x2_cluster_med$expected #not valid, but close, underpowered, explore relationship in Gorilla data

#cluster vs. age-matched medication use
#table_f_2 <- table(med_match_df$cluster5, med_match_df$med_group)
#ftable(table_f_2)
#prop.table(table_f_2)
#chisq.test(table_f_2) 
#x2_cluster_med_2 <- chisq.test(table_f_2)
#x2_cluster_med_2$expected #not valid but close, underpowered
```


# Gorilla Data: import, combine, remove outliers for RT and accuracy < .5
### Gorilla dataset cleaning was done on UNIX command line via the following workflow. More information can be found at https://github.com/HNStaggs/Gorilla-Data-Extraction:

grep -r 'orry' > vs_raw1.csv
cut -d ',' -f6,7,13,25,31,35,36,41,50,51 vs_raw1.csv > vs_prep1.csv
 grep 'response_keyboard' vs_prep1.csv > vs_clean1.csv
 sed '1s/^/date,exp_id,gor_id,task,trial_num,z_type,rt,corr,array,cond\n/' vs_clean1.csv > vs_final1.csv

grep -r 'orry' > vs_raw2.csv                                                  
cut -d ',' -f6,7,13,25,30,34,35,40,49,50 vs_raw2.csv > vs_prep2.csv
 grep 'response_keyboard' vs_prep2.csv > vs_clean2.csv
 sed '1s/^/date,exp_id,gor_id,task,trial_num,z_type,rt,corr,array,cond\n/' vs_clean2.csv > vs_final2.csv
 
 
grep -r 'orry' > vs_raw3.csv                                                  
cut -d ',' -f6,7,13,25,30,35,36,41,50,51 vs_raw3.csv > vs_prep3.csv
 grep 'response_keyboard' vs_prep3.csv > vs_clean3.csv
 sed '1s/^/date,exp_id,gor_id,task,trial_num,z_type,rt,corr,array,cond\n/' vs_clean3.csv > vs_final3.csv


# Read in data and drop NA
```{r}
vs_prep <- read_csv("C:/Users/halee/OneDrive/Desktop/vdap_vs_final.csv")
#View(vs_prep)
vs <- vs_prep %>% filter(z_type == 'response_keyboard')
#view(vs)
vs$array[vs$array == '3Image8.jpg'] <- 'small'
vs$array[vs$array == '2Image15.jpg'] <- 'large'
vs$array[vs$array == '4ImageNoTarget.jpg'] <- 'large'
vs$array[vs$array == '4Image8.jpg'] <- 'small'
vs$array[vs$array == '3Image15.jpg'] <- 'large'
vs$array[vs$array == '1Image8.jpg'] <- 'small'
vs$array[vs$array == '1Image15.jpg'] <- 'large'
vs$array[vs$array == '2ImageNT.jpg'] <- 'small'


fl <- read_csv("C:/Users/halee/OneDrive/Desktop/gor_final.csv")
g_clean <- drop_na(fl)
#View(g_clean)

```
```{r}
#separate tasks and conditions
flank_incon <- g_clean %>%
  filter(Cond == "Incongruent") %>%
  group_by(ID) %>%
  summarise(f_i_rt_mn = mean(as.numeric(RT)),
            f_i_rt_sd = sd(as.numeric(RT)),
            f_i_acc = mean(as.numeric(Ans)))
#View(flank_incon)

flank_con <- g_clean %>%
  filter(Cond == "Congruent") %>%
  group_by(ID) %>%
  summarise(f_c_rt_mn = mean(as.numeric(RT)),
            f_c_rt_sd = sd(as.numeric(RT)),
            f_c_acc = mean(as.numeric(Ans)))
#View(flank_con)


vs_absent_sm <- vs %>%
  filter(cond == "Absent" & array == 'small') %>%
  group_by(gor_id) %>%
  summarise(vs_a_rt_mn_s = mean(as.numeric(rt)),
            vs_a_rt_sd_s = sd(as.numeric(rt)),
            vs_a_acc_s = mean(as.numeric(corr)))
#View(vs_absent_sm)


vs_present_sm <- vs %>%
  filter(cond == "Present" & array == 'small') %>%
  group_by(gor_id) %>%
  summarise(vs_p_rt_mn_s = mean(as.numeric(rt)),
            vs_p_rt_sd_s = sd(as.numeric(rt)),
            vs_p_acc_s = mean(as.numeric(corr)))
#View(vs_present_sm)


vs_absent_lg <- vs %>%
  filter(cond == "Absent" & array == 'large') %>%
  group_by(gor_id) %>%
  summarise(vs_a_rt_mn_l = mean(as.numeric(rt)),
            vs_a_rt_sd_l = sd(as.numeric(rt)),
            vs_a_acc_l = mean(as.numeric(corr)))
#View(vs_absent_lg)


vs_present_lg <- vs %>%
  filter(cond == "Present" & array == 'large') %>%
  group_by(gor_id) %>%
  summarise(vs_p_rt_mn_l = mean(as.numeric(rt)),
            vs_p_rt_sd_l = sd(as.numeric(rt)),
            vs_p_acc_l = mean(as.numeric(corr)))
#View(vs_present_lg)


```



# Combine task data
```{r}
flank_sum <- cbind(flank_incon, flank_con)
#View(flank_sum)


vs_sum1 <- cbind(vs_absent_sm, vs_present_sm, vs_absent_lg, vs_present_lg)
vs_sum_final <- vs_sum1[!duplicated(as.list(vs_sum1))]
#View(vs_sum_final)
colnames(vs_sum_final)[1] <- "ID"

#drop extra ID column
flank_sum_final <- subset(flank_sum[-5])
#View(flank_sum_final)
#vs_sum_final <- subset(vs_sum[-5])
#View(vs_sum_final)

#recombine all task summaries into single dataframe and drop row 9 from flank_sum_final
flank_drop <- flank_sum_final[-9,]

cog_final <- merge(vs_sum_final, flank_sum_final, by = 'ID')
#View(cog_final)

#cog_final <- subset(cog_data[-8])
View(cog_final)

cog_final$gor_id <- cog_final$ID
```


# Merge to master dataset by matching gorilla id
```{r}
View(mood_rm_na)
mood_gor <- merge(mood_rm_na, cog_final, by = 'gor_id')
View(mood_gor)
str(mood_gor)
summary(mood_gor)
dim(mood_gor)[2]

mood_gor_anovas <- data.frame(impute(mood_gor, what = 'median'))
summary(mood_gor_anovas)

#fill NA with median values
#mood_gor$vs_a_rt_mn[is.na(mood_gor$vs_a_rt_mn)] <- median(mood_gor$vs_a_rt_mn, na.rm=TRUE)
#mood_gor$vs_a_rt_sd[is.na(mood_gor$vs_a_rt_sd)] <- median(mood_gor$vs_a_rt_sd, na.rm=TRUE)
#mood_gor$vs_a_acc[is.na(mood_gor$vs_a_acc)] <- median(mood_gor$vs_a_acc, na.rm=TRUE)

#mood_gor$vs_p_rt_mn[is.na(mood_gor$vs_p_rt_mn)] <- median(mood_gor$vs_p_rt_mn, na.rm=TRUE)
#mood_gor$vs_p_rt_sd[is.na(mood_gor$vs_p_rt_sd)] <- median(mood_gor$vs_p_rt_sd, na.rm=TRUE)
#mood_gor$vs_p_acc[is.na(mood_gor$vs_p_acc)] <- median(mood_gor$vs_p_acc, na.rm=TRUE)

#mood_gor$f_i_rt_mn[is.na(mood_gor$f_i_rt_mn)] <- median(mood_gor$f_i_rt_mn, na.rm=TRUE)
#mood_gor$f_i_rt_sd[is.na(mood_gor$f_i_rt_sd)] <- median(mood_gor$f_i_rt_sd, na.rm=TRUE)
#mood_gor$f_i_acc[is.na(mood_gor$f_i_acc)] <- median(mood_gor$f_i_acc, na.rm=TRUE)

#mood_gor$f_c_rt_mn[is.na(mood_gor$f_c_rt_mn)] <- median(mood_gor$f_c_rt_mn, na.rm=TRUE)
#mood_gor$f_c_rt_sd[is.na(mood_gor$f_c_rt_sd)] <- median(mood_gor$f_c_rt_sd, na.rm=TRUE)
#mood_gor$f_c_acc[is.na(mood_gor$f_c_acc)] <- median(mood_gor$f_c_acc, na.rm=TRUE)

#drop extra ID column
mood_gor_final <- mood_gor
View(mood_gor_final)
str(mood_gor_final)
```

```{r}
#
mood_gor_final$nicotine <- as.numeric(mood_gor_final$nicotine)
mood_gor_final$alcohol_status <- as.numeric(mood_gor_final$alcohol_status)
mood_gor_final$cannabis <- as.numeric(mood_gor_final$cannabis)

mood_gor_final$nico_bi <- if_else(mood_gor_final$nicotine  > 1,1,0)
mood_gor_final$alco_bi <- if_else(mood_gor_final$alcohol_status > 1,1,0)
mood_gor_final$cann_bi <- if_else(mood_gor_final$cannabis > 1,1,0)

mood_gor_final$nico_bi <- as.factor(mood_gor_final$nico_bi)
mood_gor_final$alco_bi <- as.factor(mood_gor_final$alco_bi)
mood_gor_final$cann_bi <- as.factor(mood_gor_final$cann_bi)

#update variable types before preprocessing
str(mood_gor_final)
prop.table(table(mood_gor_final$nico_bi))
prop.table(table(mood_gor_final$cann_bi))
prop.table(table(mood_gor_final$dropout))
#mood_gor_final$

#trans <- preProcess(mood_gor_final,
                    #method = c("BoxCox", "center", "scale"))

# Apply the transformations to the original data:
#final_trans <- predict(trans, mood_gor_final)
#View(final_trans)

#eliminate highly corr and bad variance
#degeneratecols <- nearZeroVar(final_trans)
#final_filter1 <- final_trans[,-degeneratecols]
#corrs <- select_if(final_filter1, is.numeric)
#highCorr <- findCorrelation(corrs, cutoff = .6)
#final_filter <- final_trans[, -highCorr]

#set up cross validated metrics


#run model

#test set
```



```

mood_scale2 <- as.data.frame(scale(mood_gor_final[,69:86]))


mood_scale <- cbind(mood_gor_final,mood_scale1)
View(mood_scale)

mood_scale$age.mm <- (mood_scale$age - min(mood_scale$age)) / (max(mood_scale$age) - min(mood_scale$age)) 
mood_scale$vs_a.mm <- (mood_scale$vs_a_rt_mn - min(mood_scale$vs_a_rt_mn)) / 
  (max(mood_scale$vs_a_rt_mn) - min(mood_scale$vs_a_rt_mn))

mood_scale$f_i.mm <- (mood_scale$f_i_rt_mn - min(mood_scale$f_i_rt_mn)) / 
  (max(mood_scale$f_i_rt_mn) - min(mood_scale$f_i_rt_mn))

mood_scale$pf.mm <- (mood_scale$pf_total - min(mood_scale$pf_total)) / 
  (max(mood_scale$pf_total) - min(mood_scale$pf_total))



library(caret)
set.seed(2)
split <- createDataPartition(mood_scale$rc_id, p = .67, list = FALSE, times = 1)
train <- mood_scale[split,]
test <- mood_scale[-split,]
#View(train)
#View(test)

tr_split <- round((dim(train)[1]/dim(mood_scale)[1])*100,1)
ts_split <- round((dim(test)[1]/dim(mood_scale)[1])*100,1)
tr_n <- dim(train)[1]
ts_n <- dim(test)[1]
split_train <- as.data.frame(cbind(tr_split,tr_n))
split_test <- as.data.frame(cbind(ts_split, ts_n))
split_params <- merge(split_train, split_test)
split_params
```

# Do clusterings
```{r}
#elbow method recommends 5 clusters
#fviz_nbclust(mood_scale[,81:99], kmeans, method = "wss") + geom_vline(xintercept = 6
                                                                    )

#gap statistic recommends 4 clusters
#set.seed(2)
#gap_stat <- clusGap(mood_scale[,81:99], FUN = kmeans, nstart = 50,
                    #K.max = 10, B = 1000)
#fviz_gap_stat(gap_stat)

#silhoueete

#fviz_nbclust(mood_scale[,81:99], kmeans, method='silhouette')
```

```{r}
#run K means function 5 cluster solution
View(mood_scale)
set.seed(2)
kmeans_mood6 <- kmeans(mood_scale[,87:105],centers = 6)
kmeans_mood6
fviz_cluster(kmeans_mood6, data = mood_scale[,87:105], geom = c('point','text')) + theme_minimal()

#cluster assignments as grouping variable
mood_scale$cluster <- as.factor(kmeans_mood6$cluster)
cluster <- as.factor(kmeans_mood6$cluster)

#cluster summaries
Cluster1 <- mood_scale[which(cluster == 1),]
Cluster2 <- mood_scale[which(cluster == 2),]
Cluster3 <- mood_scale[which(cluster == 3),]
Cluster4 <- mood_scale[which(cluster == 4),]
Cluster5 <- mood_scale[which(cluster == 5),]
Cluster6 <- mood_scale[which(cluster == 6),]

summary(Cluster1)
summary(Cluster2)
summary(Cluster3)
summary(Cluster4)
summary(Cluster5)
summary(Cluster6)

library(cluster)
library(factoextra)
set.seed(2)
kmeans_cog <- kmeans(mood_scale[,c(69,72,75,78,81,84)],centers = 6)

kmeans_cog
fviz_cluster(kmeans_cog, data = mood_scale[,c(69,72,75,78,81,84)], geom = c('point','text')) + theme_minimal()

mood_scale$cluster_cog <- as.factor(kmeans_cog$cluster)


```



# Create function to output outliers
```{r}
iqr_outliers <- function(var_col) {
  quant_col <- as.matrix(quantile(var_col, na.rm = TRUE))
  iqr_col <- ((quant_col[4])-(quant_col[2]))
  col_min <- as.matrix(quant_col[1])
  col_max <- as.matrix(quant_col[5])
  iqr_high <- as.matrix((quant_col[4] + (1.5*iqr_col)))
  iqr_low <- as.matrix((quant_col[2] - (1.5*iqr_col)))
  iqr_ran <- bind_cols(max(iqr_low, col_min), min(iqr_high, col_max))
  print(iqr_ran)}
```


# Find lower and upper outlier bounds for a variable
```{r}
#log transform reaction time
library(tidyverse)

mood_scale$vs_a_rt_mn_s <- log(mood_scale$vs_a_rt_mn_s)
mood_scale$vs_a_rt_mn_l <- log(mood_scale$vs_a_rt_mn_l)

mood_scale$vs_p_rt_mn_s <- log(mood_scale$vs_p_rt_mn_s)
mood_scale$vs_p_rt_mn_l <- log(mood_scale$vs_p_rt_mn_l)

mood_scale$f_i_rt_mn <- log(mood_scale$f_i_rt_mn)
mood_scale$f_c_rt_mn <- log(mood_scale$f_c_rt_mn)

a_s <- as.data.frame(iqr_outliers(mood_scale$vs_a_rt_mn_s))
a_l <- as.data.frame(iqr_outliers(mood_scale$vs_a_rt_mn_l))

p_s <- as.data.frame(iqr_outliers(mood_scale$vs_p_rt_mn_s)) 
p_l <- as.data.frame(iqr_outliers(mood_scale$vs_p_rt_mn_l)) 

i <- as.data.frame(iqr_outliers(mood_scale$f_i_rt_mn))
c <- as.data.frame(iqr_outliers(mood_scale$f_c_rt_mn))

```


# Update outlier observations to lower and upper bounds
```{r}
mood_scale$vs_a_rt_mn_s[mood_scale$vs_a_rt_mn_s < a_s[1,1]] <- a_s[1,1]
mood_scale$vs_a_rt_mn_s[mood_scale$vs_a_rt_mn_s > a_s[1,2]] <- a_s[1,2]

mood_scale$vs_a_rt_mn_l[mood_scale$vs_a_rt_mn_l < a_l[1,1]] <- a_l[1,1]
mood_scale$vs_a_rt_mn_l[mood_scale$vs_a_rt_mn_l > a_l[1,2]] <- a_l[1,2]

mood_scale$vs_p_rt_mn_s[mood_scale$vs_p_rt_mn_s < p_s[1,1]] <- p_s[1,1]
mood_scale$vs_p_rt_mn_s[mood_scale$vs_p_rt_mn_s > p_s[1,2]] <- p_s[1,2]

mood_scale$vs_p_rt_mn_l[mood_scale$vs_p_rt_mn_l < p_l[1,1]] <- p_l[1,1]
mood_scale$vs_p_rt_mn_l[mood_scale$vs_p_rt_mn_l > p_l[1,2]] <- p_l[1,2]


mood_scale$f_i_rt_mn[mood_scale$f_i_rt_mn < i[1,1]] <- i[1,1]
mood_scale$f_i_rt_mn[mood_scale$f_i_rt_mn > i[1,2]] <- i[1,2]

mood_scale$f_c_rt_mn[mood_scale$f_c_rt_mn < c[1,1]] <- c[1,1]
mood_scale$f_c_rt_mn[mood_scale$f_c_rt_mn > c[1,2]] <- c[1,2]


#remove participants with less than 30% accuracy
mood_scale <- subset(mood_scale,vs_a_acc_s > .3)
mood_scale <- subset(mood_scale,vs_p_acc_s > .3)
mood_scale <- subset(mood_scale,vs_a_acc_l > .3)
mood_scale <- subset(mood_scale,f_i_acc >= .5)



#recheck distributions
boxplot(mood_scale$vs_a_rt_mn_l) 
boxplot(mood_scale$vs_p_rt_mn_l)
boxplot(mood_scale$f_i_rt_mn) 
boxplot(mood_scale$f_c_rt_mn)

#log transform RT 
#mood_gor_final$vs_a_rt_log <- log(mood_gor_final$vs_a_rt_mn) 
#mood_gor_final$vs_p_rt_log <- log(mood_gor_final$vs_p_rt_mn)
#mood_gor_final$f_i_rt_log <- log(mood_gor_final$f_i_rt_mn) 
#mood_gor_final$f_c_rt_log <- log(mood_gor_final$f_c_rt_mn)
#gghistogram(mood_gor_final, 'vs_a_rt_log', bins = 15) 
#gghistogram(mood_gor_final, 'vs_p_rt_log', bins = 15)
#gghistogram(mood_gor_final, 'f_i_rt_log', bins = 15) 
#gghistogram(mood_gor_final, 'f_c_rt_log', bins = 15)
```


# Inferential Stats for Full Sample Reaction Time Means
```{r}
leveneTest(vs_p_rt_mn ~ cluster, mood_scale) #confirm equality of variance: equal variance
shapiro.test(mood_scale$vs_p_rt_mn) #confirm normality: not normal
kruskal.test(vs_p_rt_mn_s ~ cluster, data = mood_scale) #confirm diff: no difference between groups for present condition

leveneTest(vs_a_rt_mn ~ cluster, mood_scale) #equal variance
shapiro.test(mood_scale$vs_a_rt_mn) #not normal dist
kruskal.test(vs_a_rt_mn ~ cluster, data = mood_scale) #yes difference for absent condition
dunnTest(vs_a_rt_mn ~ cluster, data = mood_scale, method = 'bonferroni') #test what conditions are stat sig diff from each other

leveneTest(f_i_rt_mn ~ cluster5, mood_gor_final) #equal variance
shapiro.test(mood_gor_final$f_i_rt_mn) #not normal dist
kruskal.test(f_i_rt_mn ~ cluster, data = mood_scale) #no difference for incongruent condition
dunnTest(f_i_rt_mn ~ cluster, data = mood_scale, method = 'bonferroni') #test what conditions are stat sig diff from each other


leveneTest(f_c_rt_mn ~ cluster5, mood_gor_final) #equal variance
shapiro.test(mood_gor_final$f_c_rt_mn) #not normal dist
kruskal.test(f_c_rt_mn ~ cluster4, data = mood_scale) #no difference for congruent condition
```


# Inferential stats for accuracy
```{r}
leveneTest(vs_p_acc ~ cluster5, mood_gor_final) #equal variance
shapiro.test(mood_gor_final$vs_p_acc) #not normal
kruskal.test(vs_p_acc ~ cluster, data = mood_scale) #no diff for present

leveneTest(vs_a_acc ~ cluster5, mood_gor_final) #equal variance
shapiro.test(mood_gor_final$vs_a_acc) #not normal dist
kruskal.test(vs_a_acc ~ cluster, data = mood_scale) #no diff for absent

leveneTest(f_i_acc ~ cluster5, mood_gor_final) #equal variance
shapiro.test(mood_gor_final$f_i_acc) #not normal dist
kruskal.test(f_i_acc ~ cluster, data = mood_scale) #no difference for incongruent


leveneTest(f_c_acc ~ cluster5, mood_gor_final) #equal variance
shapiro.test(mood_gor_final$f_c_acc) #not normal dist
kruskal.test(f_c_acc ~ cluster, data = mood_scale) #no difference for congruent
```


# Follow up for visual search absent condition
```{r}
#test intercept model: cluster
model1 <- lmer(formula = vs_a_rt_mn ~ 1 + (1|cluster5), 
               data = mood_gor_final)
summary(model1)
performance::icc(model1)
```

```{r}
#linear model

linear <- lm(f_i_acc ~ f_i_rt_mn + pre_race + verify_veteran, data = train)
summary(linear)
```

```{r}
library(neuralnet)
library(nnet)
library(NeuralNetTools)
set.seed(2)
nn <- nnet::multinom(cluster ~ vs_a_rt_mn_s + vs, data=train, size = 1)
summary(nn)
plotnet(nn)

predicted.classes <- nn %>% predict(test)
head(predicted.classes)
# Model accuracy
mean(predicted.classes == test$cluster)

```

```{r}
library(randomForest)
rf <- randomForest(formula = cluster_cog ~ age + verify_veteran + sex + ethnicity + pre_race + area_type + edu_2 +
                    nicotine + alcohol_status + cannabis + psychiatric_hist_status + pf_total + drive + fun + reward +
                    bis + masq_anxious + masq_arousal + masq_anhedonic + debq_restrained + debq_emotional + debq_external +
                    phq1 + phq2 + phq3 + phq4 + phq5 + phq6 + phq7 + phq8 + gad1 + gad2 + gad3 + gad4 + gad5 + gad6 + gad7,
                    data = train, ntree = 1000, type = 'classification')
rf
```


```{r}
#plot results
ggplot(data = mood_scale,aes(x = age, y = pf_total, col = as.factor(cluster))) +
  geom_point(size = 1, alpha= .7, position = "jitter") +
  geom_smooth(method = lm, se = T, size = 1.5, linetype = 1, alpha = .7) +
  theme_minimal() +
  labs(title = "Linear Relationship Between Age and Reaction Time for Five Clusters", xlab = 'Age', ylab = 'Reaction Time (ms)')

ggplot(data = mood_scale,aes(x = f_c_acc, y = f_c_rt_mn, col = as.factor(cluster))) +
  geom_point(size = 1, alpha= .7, position = "jitter") +
  geom_smooth(method = lm, se = T, size = 1.5, linetype = 1, alpha = .7) +
  theme_minimal() +
  labs(title = "Linear Relationship Between Age and Reaction Time for Four Clusters", xlab = 'Age', ylab = 'Reaction Time (ms)')


ggplot(data = mood_gor_final,aes(x = phq_score, y = gad_score, col = as.factor(cluster5))) +
  geom_point(size = 1, alpha= .7, position = "jitter") +
  geom_smooth(method = lm, se = T, size = 1.5, linetype = 1, alpha = .7) +
  theme_minimal() +
  labs(title = "Linear Relationship Between Mood Scores for Five Clusters", xlab = 'PHQ Score', ylab = 'GAD Score')

ggplot(data = mood_scale,aes(x = vs_a_rt_mn_l, y = vs_p_rt_mn_l, col = cluster_cog)) +
  geom_point(size = 1, alpha= .7, position = "jitter") +
  geom_smooth(method = lm, se = T, size = 1.5, linetype = 1, alpha = .7) +
  theme_minimal() +
  labs(title = "Linear Relationship Between Visual Search Conditions by Cluster", x = 'Absent Condition RT (msec)', y = 'Present Condition RT (msec)')


ggplot(data = mood_scale,aes(x = f_i_rt_mn, y = f_c_rt_mn, col = cluster_cog)) +
  geom_point(size = 1, alpha= .7, position = "jitter") +
  geom_smooth(method = lm, se = T, size = 1.5, linetype = 1, alpha = .7) +
  theme_minimal() +
  labs(title = "Linear Relationship Between Flanker Conditions by Cluster", 
       x = 'Incongruent Condition RT(msec)', y = 'Congruent Condition RT(msec)')


```

```{r}
#Random forest with XGboost
library(xgboost) 
library(Metrics)
library(caret)
train_xgb_prep <- train[,c(70,73,76,79,82,85)]
train_xgb_prep$sex[train_xgb_prep$sex == 1] <- 0
train_xgb_prep$sex[train_xgb_prep$sex == 2] <- 1
train_xgb_prep$ethnicity[train_xgb_prep$ethnicity == 1] <- 0
train_xgb_prep$ethnicity[train_xgb_prep$ethnicity == 2] <- 1

dummy <- dummyVars(" ~ .", data=train_xgb_prep)
train_xgb <- data.frame(predict(dummy, newdata = train_xgb_prep)) 
train_xgb[is.na(train_xgb)] <- 0
View(train_xgb)

test_xgb_prep <- test[,c(70,73,76,79,82,85)]
test_xgb_prep$sex[test_xgb_prep$sex == 1] <- 0
test_xgb_prep$sex[test_xgb_prep$sex == 2] <- 1
test_xgb_prep$ethnicity[test_xgb_prep$ethnicity == 1] <- 0
test_xgb_prep$ethnicity[test_xgb_prep$ethnicity == 2] <- 1
#relabel clusters starting at 0


dummy <- dummyVars(" ~ .", data=test_xgb_prep)
test_xgb <- data.frame(predict(dummy, newdata = test_xgb_prep)) 
test_xgb[is.na(test_xgb)] <- 0

y_xgb <- as.integer(train[,106])-1
y_xgb_test <- as.integer(test[,106])-1
y_xgb_test

xgboost_train = xgb.DMatrix(data=as.matrix(train_xgb_prep), label=y_xgb)
xgboost_test = xgb.DMatrix(data=as.matrix(test_xgb_prep), label=y_xgb_test)


set.seed(12)
xgb <- xgboost(data = xgboost_train, nround = 60)
rmse(y_xgb_test, predict(xgb, as.matrix(test_xgb_prep)))
predict <- predict(xgb, xgboost_test)
predict
pred_y = as.factor(round(predict))
print(pred_y)
confusionMatrix(y_xgb_test, pred_y)


params = list(
  booster="gbtree",
  eta=0.001,
  max_depth=5,
  colsample_bytree=1,
  objective="multi:softprob",
  eval_metric="mlogloss",
  num_class=6
)

set.seed(12)
xgb.fit=xgb.train(
  params=params,
  data=xgboost_train,
  nrounds=10000,
  early_stopping_rounds=10,
  watchlist=list(val1=xgboost_train,val2=xgboost_test),
  verbose=0
)

xgb.fit


xgb.pred = predict(xgb.fit,as.matrix(test_xgb_prep),reshape=T)
xgb.pred = as.data.frame(xgb.pred)
colnames(xgb.pred) = levels(as.factor(y_xgb_test))


xgb.pred$prediction = apply(xgb.pred,1,function(x) colnames(xgb.pred)[which.max(x)])
xgb.pred$label = levels(as.factor(y_xgb_test))[y_xgb_test+1]
xgb.pred$prediction
xgb.pred$label

result = sum(xgb.pred$prediction==xgb.pred$label)/nrow(xgb.pred)
print(paste("Final Accuracy =",sprintf("%1.2f%%", 100*result)))

library(caret)
confusionMatrix(xgb.pred$label2, xgb.pred$prediction)
confu
```
```{r}
install.packages('class')
library(class)
set.seed(1)
train_pred <- knn(scale(train[,69:86]), scale(train[,69:86]), train$cluster, k=50)
train_acc <- mean(train_pred == train$cluster)
train_acc

set.seed(1)
valid_pred <- predict(train_pred, newdata = scale(test[,69:86]))
valid_acc <- mean(valid_pred == valid$Outcome)

cat('Training Accuracy:   ', train_acc, '\n',
    'Validation Accuracy: ', valid_acc, sep='')


```




```{r}
library(randomForest)
library(caret)
train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                           number=10, # number of folds
                           search = "random", # we are performing a "random
                           )
set.seed(1)
model_rf <- train(cluster_cog ~ age + verify_veteran + sex + ethnicity + pre_race + area_type + edu_2 +
                    nicotine + alcohol_status + cannabis + psychiatric_hist_status + pf_total + drive + fun + reward +
                    bis + masq_anxious + masq_arousal + masq_anhedonic + debq_restrained + debq_emotional + debq_external +
                    phq1 + phq2 + phq3 + phq4 + phq5 + phq6 + phq7 + phq8 + gad1 + gad2 + gad3 + gad4 + gad5 + gad6 + gad7,
                       data = train,
                       method = "rf",
                       metric = "Accuracy",
                       trControl = train_ctrl,
                       ntree = 1000,
                       keep.forest=TRUE,
                       importance=TRUE) 


model_rf




```

# Classification of Drop Out
```{r}
library(tidyverse)
#read in file
vdap <- read_csv("C:/Users/halee/OneDrive/Documents/VDAP_DATA_FINAL/vdap_cut.csv")


pilot <- vdap %>% filter(rc_id <= 311)
post <- vdap %>% filter(rc_id > 311)
View(post)

pilot <- pilot[-c(1:3), ]

View(pilot)
pilot$gor_id[is.na(pilot$gor_id)] <- 0
pilot$nicotine[is.na(pilot$nicotine)] <- 0
pilot$cannabis[is.na(pilot$cannabis)] <- 0
pilot$nico_bi <- if_else(pilot$nicotine > 0, 1, 0)
pilot$cann_bi <- if_else(pilot$cannabis > 0, 1, 0)
pilot$dropout <- if_else(pilot$gor_id == 0, 1, 0)


table(pilot$sex)
prop.table(table(pilot$sex))

table(pilot$ethnicity)
prop.table(table(pilot$ethnicity))

table(pilot$area_type)
prop.table(table(pilot$area_type))

table(pilot$psychiatric_hist_status)
prop.table(table(pilot$psychiatric_hist_status))

table(pilot$pre_race)
prop.table(table(pilot$pre_race))

table(pilot$edu_2)
prop.table(table(pilot$edu_2))

table(pilot$nico_bi)
prop.table(table(pilot$nico_bi))

table(pilot$cann_bi)
prop.table(table(pilot$cann_bi))

table(pilot$dropout)
prop.table(table(pilot$dropout))



post$gor_id[is.na(post$gor_id)] <- 0
post$nicotine[is.na(post$nicotine)] <- 0
post$cannabis[is.na(post$cannabis)] <- 0
post$nico_bi <- if_else(post$nicotine > 0, 1, 0)
post$cann_bi <- if_else(post$cannabis > 0, 1, 0)
post$dropout <- if_else(post$gor_id == 0, 1, 0)
#update missing vet values
#Ids: 328, 336,338,359,384,395,451,595,749
post[3,4] <- 1
post[6,4] <- 1
post[8,4] <- 1
post[23,4] <- 1
post[31,4] <- 1
post[35,4] <- 1
post[53,4] <- 1
post[92,4] <- 1
post[111,4] <- 1

post$verify_veteran[is.na(post$verify_veteran)] <- 0

post_vet <- post %>% filter(verify_veteran == 1)
post_civ <- post %>% filter(verify_veteran == 0)


mean(pilot$age)
sd(pilot$age)
mean(post_civ$age)
sd(post_civ$age)
mean(post_vet$age)
sd(post_vet$age)

vdap$age[is.na(vdap$age)] <- median(vdap$age, na.rm = TRUE)

mean(vdap$age)
sd(vdap$age)

dim(post_vet)

table(post_vet$sex)
prop.table(table(post_vet$sex))

table(post_vet$ethnicity)
prop.table(table(post_vet$ethnicity))

table(post_vet$area_type)
prop.table(table(post_vet$area_type))

table(post_vet$psychiatric_hist_status)
prop.table(table(post_vet$psychiatric_hist_status))

table(post_vet$pre_race)
prop.table(table(post_vet$pre_race))

table(post_vet$edu_2)
prop.table(table(post_vet$edu_2))

table(post_vet$nico_bi)
prop.table(table(post_vet$nico_bi))

table(post_vet$cann_bi)
prop.table(table(post_vet$cann_bi))

table(post_vet$dropout)
prop.table(table(post_vet$dropout))


dim(post_civ)
table(post_civ$sex)
prop.table(table(post_civ$sex))

table(post_civ$ethnicity)
prop.table(table(post_civ$ethnicity))

table(post_civ$area_type)
prop.table(table(post_civ$area_type))

table(post_civ$psychiatric_hist_status)
prop.table(table(post_civ$psychiatric_hist_status))

table(post_civ$pre_race)
prop.table(table(post_civ$pre_race))

table(post_civ$edu_2)
prop.table(table(post_civ$edu_2))

table(post_civ$nico_bi)
prop.table(table(post_civ$nico_bi))

table(post_civ$cann_bi)
prop.table(table(post_civ$cann_bi))

table(post_civ$dropout)
prop.table(table(post_civ$dropout))



summary(post)


post <- post[, c(1:8,10:14,38)]
pilot <- pilot[, c(1:8,10:14,38)]


c50_data <- rbind(post, pilot)
View(c50_data)

c50_vet <- c50_data %>% filter(verify_veteran == 1)
c50_civ <- c50_data %>% filter(verify_veteran == 0)

anova_data <- c50_data %>% filter(dropout == 0)

c50_drop <-c50_data %>% filter(dropout == 1)

c50_comp <-c50_data %>% filter(dropout == 0)


chisq.test(table(c50_data$dropout, c50_data$verify_veteran)) 
chisq.test(table(c50_data$dropout, c50_data$sex)) 
chisq.test(table(c50_data$dropout, c50_data$ethnicity))
chisq.test(table(c50_data$dropout, c50_data$area_type))
chisq.test(table(c50_data$dropout,c50_data$psychiatric_hist_status))
chisq.test(table(c50_data$dropout, c50_data$nico_bi))
chisq.test(table(c50_data$dropout, c50_data$cann_bi))
chisq.test(table(c50_data$dropout, c50_data$edu_2))
t.test(c50_drop$age, c50_comp$age)


chisq.test(table(c50_data$verify_veteran, c50_data$sex)) 
chisq.test(table(c50_data$verify_veteran, c50_data$ethnicity))
chisq.test(table(c50_data$verify_veteran, c50_data$area_type))
chisq.test(table(c50_data$verify_veteran,c50_data$psychiatric_hist_status))
chisq.test(table(c50_data$verify_veteran, c50_data$nico_bi))
chisq.test(table(c50_data$verify_veteran, c50_data$cann_bi))
chisq.test(table(c50_data$verify_veteran, c50_data$edu_2))
chisq.test(table(c50_data$verify_veteran, c50_data$pre_race))
t.test(c50_vet$age, c50_civ$age)

c50_race <- c50_data %>% filter(pre_race != 7)
chisq.test(table(c50_race$verify_veteran, c50_race$pre_race))
chisq.test(table(c50_race$dropout, c50_race$pre_race))

table(c50_data$verify_veteran, c50_data$pre_race)

table(c50_data$verify_veteran, c50_data$dropout)

pwr.anova.test(k=4,f=.6,sig.level=.05,power=.8)


table(c50_comp$nico_bi)
#oneway.test(c50_data$


nico_no <- tree_data %>% filter(nico_bi == 0)
nico_yes_cann_no <- tree_data %>% filter(nico_bi == 1 & cann_bi == 0)
nico_yes_cann_yes <- tree_data %>% filter(nico_bi == 1 & cann_bi == 1)

table(nico_no$dropout)
table(nico_yes_cann_no$dropout)
table(nico_yes_cann_yes$dropout)

#COg anovas
cog_comp <- merge(c50_data, cog_final, by = 'gor_id')
View(cog_comp)
cog_comp$verify_veteran[is.na(cog_comp$verify_veteran)] <- 1
cog_comp$both_bi <- if_else(cog_comp$nico_bi == 1 | cog_comp$cann_bi == 1, 1, 0)
View(cog_comp$both_bi)

table(cog_comp$both_bi)

summary(cog_comp)

oneway.test(log(cog_comp$vs_a_rt_mn_l) ~ cog_comp$both_bi)
oneway.test(log(cog_comp$vs_p_rt_mn_l) ~ cog_comp$both_bi)
oneway.test(log(cog_comp$f_i_rt_mn) ~ cog_comp$both_bi)
oneway.test(log(cog_comp$f_c_rt_mn) ~ cog_comp$both_bi)
kruskal.test(cog_comp$vs_a_acc_l, cog_comp$both_bi)
kruskal.test(cog_comp$vs_p_acc_l, cog_comp$both_bi)

kruskal.test(cog_comp$f_i_acc, cog_comp$both_bi)
kruskal.test(cog_comp$f_c_acc, cog_comp$both_bi)




#verify data types and missing values
summary(vdap)
View(vdap)
dim(vdap)[1]


#update people without gorilla ID to a zero
vdap$gor_id[is.na(vdap$gor_id)] <- 0

#create new variable for target feature (dropout)
#assign those with a zero gorilla ID to a 1 (dropout) and those with a Gorilla ID to a 0 (no dropout)
vdap$dropout <- if_else(vdap$gor_id == 0, 1, 0)

#fill in NA values with medians
vdap$age[is.na(vdap$age)] <- median(vdap$age, na.rm=TRUE)
vdap$sex[is.na(vdap$sex)] <- max(vdap$sex, na.rm = TRUE)
vdap$ethnicity[is.na(vdap$ethnicity)] <- median(vdap$ethnicity, na.rm = TRUE)
vdap$pre_race[is.na(vdap$pre_race)] <- median(vdap$pre_race, na.rm = TRUE)
vdap$area_type[is.na(vdap$area_type)] <- median(vdap$area_type, na.rm = TRUE)
vdap$edu_1[is.na(vdap$edu_1)] <- median(vdap$edu_1, na.rm = TRUE)
vdap$edu_2[is.na(vdap$edu_2)] <- median(vdap$edu_2, na.rm = TRUE)
vdap$alcohol_status[is.na(vdap$alcohol_status)] <- median(vdap$alcohol_status, na.rm = TRUE)
vdap$psychiatric_hist_status[is.na(vdap$psychiatric_hist_status)] <- min(vdap$psychiatric_hist_status, na.rm = TRUE)
vdap$verify_veteran[is.na(vdap$verify_veteran)] <- max(vdap$verify_veteran, na.rm=TRUE)
vdap$pf_total[is.na(vdap$pf_total)] <- median(vdap$pf_total, na.rm = TRUE)
vdap$drive[is.na(vdap$drive)] <- median(vdap$drive, na.rm = TRUE)
vdap$fun[is.na(vdap$fun)] <- median(vdap$fun, na.rm = TRUE)
vdap$reward[is.na(vdap$reward)] <- median(vdap$reward, na.rm = TRUE)
vdap$bis[is.na(vdap$bis)] <- median(vdap$bis, na.rm = TRUE)
vdap$bis_total[is.na(vdap$bis_total)] <- median(vdap$bis_total, na.rm = TRUE)
vdap$nicotine[is.na(vdap$nicotine)] <- median(vdap$nicotine, na.rm=TRUE)
vdap$cannabis[is.na(vdap$cannabis)] <- median(vdap$cannabis, na.rm=TRUE)
vdap$masq_anxious[is.na(vdap$masq_anxious)] <- median(vdap$masq_anxious, na.rm=TRUE)
vdap$masq_arousal[is.na(vdap$masq_arousal)] <- median(vdap$masq_arousal, na.rm=TRUE)
vdap$masq_anhedonic[is.na(vdap$masq_anhedonic)] <- median(vdap$masq_anhedonic, na.rm=TRUE)
vdap$masq_total[is.na(vdap$masq_total)] <- median(vdap$masq_total, na.rm=TRUE)
vdap$debq_restrained[is.na(vdap$debq_restrained)] <- median(vdap$debq_restrained, na.rm=TRUE)
vdap$debq_emotional[is.na(vdap$debq_emotional)] <- median(vdap$debq_emotional, na.rm=TRUE)
vdap$debq_external[is.na(vdap$debq_external)] <- median(vdap$debq_external, na.rm=TRUE)
vdap$debq_total[is.na(vdap$debq_total)] <- median(vdap$debq_total, na.rm=TRUE)
vdap$meds[is.na(vdap$meds)] <- 0
vdap$med1[is.na(vdap$med1)] <- 0
vdap$med2[is.na(vdap$med2)] <- 0
vdap$med3[is.na(vdap$med3)] <- 0
vdap$med4[is.na(vdap$med4)] <- 0
vdap$med5[is.na(vdap$med5)] <- 0
vdap$med6[is.na(vdap$med6)] <- 0
vdap$med98[is.na(vdap$med98)] <- 0
#vdap$mdd[is.na(vdap$mdd)] <- 0
#vdap$mad[is.na(vdap$mad)] <- 0
#vdap$ptsd[is.na(vdap$ptsd)] <- 0
#vdap$adhd[is.na(vdap$adhd)] <- 0
#vdap$bipol[is.na(vdap$bipol)] <- 0
#vdap$pd[is.na(vdap$pd)] <- 0
#vdap$diag_year[is.na(vdap$diag_year)] <- median(vdap$diag_year, na.rm=TRUE)

#update data types to factors as applicable 
vdap$verify_veteran <- as.factor(vdap$verify_veteran)
vdap$sex <- as.factor(vdap$sex)
vdap$ethnicity <- as.factor(vdap$ethnicity)
vdap$pre_race <- as.factor(vdap$pre_race)
vdap$area_type <- as.factor(vdap$area_type)
vdap$edu_1 <- as.factor(vdap$edu_1)
vdap$edu_2 <- as.factor(vdap$edu_2)
vdap$nicotine <- as.factor(vdap$nicotine)
vdap$alcohol_status <- as.factor(vdap$alcohol_status)
vdap$cannabis <- as.factor(vdap$cannabis)
vdap$psychiatric_hist_status <- as.factor(vdap$psychiatric_hist_status)


#create variable for total amount of meds
vdap$med_total <- vdap$med1 + vdap$med2 + vdap$med4 + vdap$med5

View(vdap)


#Demo table for split sample

vets <- vdap %>% filter(verify_veteran == 1)
civs <- vdap %>% filter(verify_veteran == 0)

dim(vets)[1]
dim(civs)[1]




#create variable for total amount of axis 1 disorders
#vdap$axis1 <- vdap$mdd + vdap$mad + vdap$ptsd + vdap$adhd + vdap$bipol + vdap$pd

#update med and mood disorders variables to factors
#vdap$meds <- as.factor(vdap$meds)
#vdap$med1 <- as.factor(vdap$med1)
#vdap$med2 <- as.factor(vdap$med2)
#vdap$med3 <- as.factor(vdap$med3)
#vdap$med4 <- as.factor(vdap$med4)
#vdap$med5 <- as.factor(vdap$med5)
#vdap$med6 <- as.factor(vdap$med6)
#vdap$med98 <- as.factor(vdap$med98)
#vdap$mdd <- as.factor(vdap$mdd)
#vdap$mad <- as.factor(vdap$mad)
#vdap$ptsd <- as.factor(vdap$ptsd)
#vdap$adhd <- as.factor(vdap$adhd)
#vdap$bipol <- as.factor(vdap$bipol)
#vdap$pd <- as.factor(vdap$pd)

#verify data types and missing values
#summary(vdap)

#update output variable to factor
vdap$dropout <- as.factor(vdap$dropout)

#separate variables for modeling
vdap_preds <- vdap[,c(1:28,61,62)]
View(vdap_preds)

#check out distributions of numerical variables
library(Hmisc)
library(ggpubr)
vdap_z <- as.data.frame(scale(vdap_preds[,c(3,15:28,30)], center = TRUE, scale = TRUE))
View(vdap_z)
vdap_z$dropout <- vdap_preds$dropout
hist(vdap_z[,c(1:8)])
hist(vdap_z[,c(9:16)])

#check for skewness of numerical variables
library(e1071)
skews1 <- lapply(vdap_z[c(1:16)],skewness)

#transform numerical variables to be normalized
age_t <- BoxCoxTrans(vdap_z$age)
age_tr <- predict(age_t, vdap_z$age)

pf_t <- BoxCoxTrans(vdap_z$pf_total)
pf_tr <- predict(pf_t, vdap_z$pf_total)

dr_t <- BoxCoxTrans(vdap_z$drive)
dr_tr <- predict(dr_t, vdap_z$drive)

fn_t <- BoxCoxTrans(vdap_z$fun)
fn_tr <- predict(fn_t, vdap_z$fun)

rd_t <- BoxCoxTrans(vdap_z$reward)
rd_tr <- predict(rd_t, vdap_z$reward)

bs_t <- BoxCoxTrans(vdap_z$bis)
bs_tr <- predict(bs_t, vdap_z$bis)

bt_t <- BoxCoxTrans(vdap_z$bis_total)
bt_tr <- predict(bt_t, vdap_z$bis_total)

max_t <- BoxCoxTrans(vdap_z$masq_anxious)
max_tr <- predict(max_t, vdap_z$masq_anxious)

mar_t <- BoxCoxTrans(vdap_z$masq_arousal)
mar_tr <- predict(mar_t, vdap_z$masq_arousal)

man_t <- BoxCoxTrans(vdap_z$masq_anhedonic)
man_tr <- predict(man_t, vdap_z$masq_anhedonic)

mt_t <- BoxCoxTrans(vdap_z$masq_total)
mt_tr <- predict(mt_t, vdap_z$masq_total)

dr_t <- BoxCoxTrans(vdap_z$debq_restrained)
dr_tr <- predict(dr_t, vdap_z$debq_restrained)

dem_t <- BoxCoxTrans(vdap_z$debq_emotional)
dem_tr <- predict(dem_t, vdap_z$debq_emotional)

dex_t <- BoxCoxTrans(vdap_z$debq_external)
dex_tr <- predict(dex_t, vdap_z$debq_external)

dt_t <- BoxCoxTrans(vdap_z$debq_total)
dt_tr <- predict(dt_t, vdap_z$debq_total)

med_t <- BoxCoxTrans(vdap_z$med_total)
med_tr <- predict(med_t, vdap_z$med_total)

#verify skews to see if transformation is needed
age_t
pf_t
dr_t
fn_t
rd_t
bs_t
bt_t
max_t
mar_t
man_t 
mt_t
dr_t
dem_t
dex_t
dt_t
med_t

#check for corrs among numerical variables
library(corrplot)
corrplot(cor(vdap_z[,c(1:16)]), method = 'color')

#trim highly correlated variables 
library(caret)
vdap_corr <- findCorrelation(cor(vdap_z[,c(1:16)]), cutoff = 0.7)
vdap_trim1 <- vdap_z[,-vdap_corr]
View(vdap_trim1)
corrplot(cor(vdap_trim1[,-14]), method = 'number')

#explore categorical data with proportions to droput
prop.table(table(vdap$dropout, vdap$verify_veteran))
prop.table(table(vdap$dropout, vdap$sex))
prop.table(table(vdap$dropout, vdap$ethnicity))
prop.table(table(vdap$dropout, vdap$pre_race))
prop.table(table(vdap$dropout, vdap$area_type))
prop.table(table(vdap$dropout, vdap$edu_2))
prop.table(table(vdap$dropout, vdap$nicotine))
prop.table(table(vdap$dropout, vdap$alcohol_status))
prop.table(table(vdap$dropout, vdap$cannabis))
prop.table(table(vdap$dropout, vdap$psychiatric_hist_status))

#add categorical data back to dataframe
vdap_trim1$vet <- vdap$verify_veteran
vdap_trim1$sex <- vdap$sex
vdap_trim1$ethn <- vdap$ethnicity
vdap_trim1$race <- vdap$pre_race
vdap_trim1$area <- vdap$area_type
vdap_trim1$edu <- vdap$edu_2
vdap_trim1$nico <- vdap$nicotine
vdap_trim1$alco <- vdap$alcohol_status
vdap_trim1$cann <- vdap$cannabis
vdap_trim1$psy <- vdap$psychiatric_hist_status

#baseline is prop of dropout == 1
# accuracy must beat 22.9%
prop.table(table(vdap_trim1[,14]))
table(vdap_trim1$dropout)

#trim variables categorical only
View(vdap_trim1)
vdap_trim2 <- vdap_trim1[,c(1,15:24,14)]
View(vdap_trim2)

vdap_trim2$nico <- as.numeric(vdap_trim2$nico)
vdap_trim2$alco <- as.numeric(vdap_trim2$alco)
vdap_trim2$cann <- as.numeric(vdap_trim2$cann)

vdap_trim2$nico_bi <- if_else(vdap_trim2$nico > 1,1,0)
vdap_trim2$alco_bi <- if_else(vdap_trim2$alco > 1,1,0)
vdap_trim2$cann_bi <- if_else(vdap_trim2$cann > 1,1,0)

vdap_trim2$nico_bi <- as.factor(vdap_trim2$nico_bi)
vdap_trim2$alco_bi <- as.factor(vdap_trim2$alco_bi)
vdap_trim2$cann_bi <- as.factor(vdap_trim2$cann_bi)


vdap_trim3 <- vdap_trim2[,c(1:7,13:15,12)]
View(vdap_trim3)

#vdap_trim3$dropout <- factor(vdap_trim3$dropout, levels = c('1','0'))

#split data into training and test sets
set.seed(2)
data_split <- createDataPartition(vdap_trim3$dropout, p = .7, list = FALSE, times = 1)
vdap_train <- vdap_trim3[data_split,]
vdap_test <- vdap_trim3[-data_split,]
#verify split proportions
dim(vdap_train)[1]
dim(vdap_test)[1]

prop.table(table(vdap_train$dropout))
prop.table(table(vdap_test$dropout))
View(vdap_train)

#rebalance training set to be 45% positive class
#need 71 records in training set
rebal_n <- ((0.45*(dim(vdap_train)[1]))-length(vdap_train$dropout[vdap_train$dropout == 1]))/0.55 
rebal_n
to.resample <- which(vdap_train$dropout == 1) 
our.resample <- sample(x = to.resample, size = 71, replace = TRUE) 
our.resample <- vdap_train[our.resample,]
train_rebal <- rbind(vdap_train, our.resample)
table <- table(train_rebal$dropout) 
table2 <- rbind(table, round(prop.table(table),4)) 
colnames(table2) <- c('Dropout = No','Dropout = Yes')
rownames(table2) <- c('Count','Proportion') 
table2

prop.table(table(vdap$area_type))
prop.table(table(vdap$verify_veteran))
prop.table(table(vdap$psychiatric_hist_status))


logreg <- glm(dropout ~ . , data = vdap_trim3, family = 'binomial'(link = 'logit'))
summary(logreg)

View(c50_data)

install.packages('adabag')
install.packages('htmltools', version = '0.5.4')
library(adabag)
library(caret)
library(rpart)
tree_data$dropout <- as.factor(tree_data$dropout)


boost <- boosting(dropout ~ ., data = tree_data, mfinal = 3)
boost
summary(boost)
boost.

library(C50)
tree_data$dropout <- factor(tree_data$dropout, levels = c(0,1))

set.seed(2)
c50 <- C5.0(dropout ~ . , data = tree_data, control = C5.0Control(minCases = 8))
c50
c50_plot <- plot(c50)
plot(c50)

summary(c50)
summary(c50)
c50_imp <- varImp(c50)
c50_imp

test <- predict(object = c50, newdata = vdap_test)
confusionMatrix(test, vdap_test$dropout)
tb <- table(test, vdap_test$dropout)
TN_c5 <- tb[1,1]
FN_c5 <- tb[2,1]
FP_c5 <- tb[1,2]
TP_c5 <- tb[2,2]
accuracy_c5 <- round((((TP_c5+TN_c5) / (TP_c5 + TN_c5 + FP_c5 + FN_c5)))*100,2)
accuracy_c5
vdap_test$c50pred <- factor(test, ordered = TRUE)
library(pROC)
c50ROC <- roc(vdap_test$dropout ~ vdap_test$c50pred,plot=TRUE,print.auc=TRUE,
col="green",lwd=4,print.auc.y=0.4,
main="C5.0 ROC Curve")



tree_data <- c50_data[, c(3:8, 10, 14, 61:63)]
View(tree_data)
tree_data$verify_veteran[is.na(tree_data$verify_veteran)] <- 1
tree_data$dropout <- factor(tree_data$dropout, levels = c('Yes','No'))

train_y <- factor(tree_data[,11], levels = c('Yes','No'))
train_x <- tree_data[,-11]
install.packages('adabag')


library(caret)
library(C50)
library(mlbench)
folds_df <- createFolds(tree_data$dropout, returnTrain = TRUE)
ctrl <- trainControl(method = "cv", 
                        number = 10,
                        trials = 100,
                        summaryFunction = twoClassSummary,
                        classProbs = TRUE,
                        savePredictions = TRUE)

set.seed(2)
c50 <- train(x = train_x, y = train_y, method='adaboost', metric='ROC', trControl = ctrl)
# Check out model performance, train ROC, sens, spec
c50
plot(c50)
# visualize the resample distributions
xyplot(mdl,type = c("g", "p", "smooth"))



```


# Cognitive performance of smokers

```{r}
View(vdap_train)
vdap_train$both_bi <- if_else(vdap_train$nico_bi == 1 | vdap_train$cann_bi == 1, 1, 0)
prop.table(table(vdap_train$both_bi))
table(vdap_train$both_bi)



version(tidyverse)
tidyverse

??tidyverse
citation(package = 'tidyverse')
packageVersion('tidyverse')
packageVersion('ggplot2')
citation(package = 'ggplot2')

packageVersion('C50')
citation(package = 'C50')

packageVersion('stats')
citation(package = 'stats')

packageVersion('pwr')
citation(package = 'pwr')

install.packages(pwr)
library(pwr)

pwr.2p2n.test(h = NULL, n1 = 26, n2 = , power = 0.8, alternative = 'greater')



pwr.2p2n.test(sig.level=.05,power=.8)


```
